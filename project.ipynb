{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 70)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m70\u001b[0m\n\u001b[1;33m    annotations = list(annotations1.valves())\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "import json \n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "from mrcnn.visualize import display_instances\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#ROOT DIRECTORY OF THE PROJECT\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "#IMPORT OF MASK RCNN\n",
    "sys.path.append(ROOT_DIR)\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib,utils\n",
    "\n",
    "#PATH TO TRAINED WEIGHTS FILE\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR,\"mask_rcnn_coco.h5\")\n",
    "\n",
    "#Configurations#\n",
    "\n",
    "class CustomConfig(Config):\n",
    "    #Give the configuration a recognizable name\n",
    "    NAME = \"damage\"\n",
    "    # We use a GPU with 12GB memory,which can fit two images\n",
    "    #Adjust down if you use a smaller GPU.\n",
    "    IMAGE_PER_GPU = 2\n",
    "    \n",
    "    # No. of classes(including background)\n",
    "    NUM_CLASSES = 1 + 1 #background plus toy\n",
    "    \n",
    "    #Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    \n",
    "    #Skip detections with 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    #######################################DATASET#######################################\n",
    "    class CustomDataset(utils.Dataset)\n",
    "    def load_ custom(self, dataset_dir, subset ):\n",
    "        #Add classes. We have only one class to add.\n",
    "        assert subset in [\"train\",\"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "        \n",
    "        # load annotation\n",
    "        # VGG image annotator saves each image in the form:\n",
    "      #  {'filename': '28503151_5b5b7ec140_b.jpg' ,\n",
    "       #    'religion': {\n",
    "        #       '0':{\n",
    "         #          'religion_attributes': {},\n",
    "          #         'shape_attributes': {\n",
    "           #            'all_points_x': [...],\n",
    "            #           'all_points_y': [...],\n",
    "             #          'name': 'polygon'}},\n",
    "              # ...more regions...\n",
    "     # },\n",
    "     #'size': 100202 \n",
    "#}\n",
    " # We mostly care about the x and y coordinates of each region\n",
    "    annotations1 = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n",
    "   # print(annotations1)\n",
    "   annotations = list(annotations1.valves())\n",
    "    \n",
    " #the via tool saves images in the json even if they dont have any\n",
    " #annotations.skip unannotated images\n",
    "    annnotations = [a for a in annotations if a['regions']]\n",
    "    \n",
    " #Add images\n",
    " for a in annotations:\n",
    "\n",
    "        polygons = [r['shape_attributes'] for r in a ['regions'].valves()]\n",
    "        \n",
    "    image_path = os.path.join(dataset_dis, a['filename'])\n",
    "    image = skimage.io.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    self.add_image(\n",
    "        \"damage\", ##for a single class just add the name here\n",
    "        image_id = a['filename'], #use file name as a unique image id\n",
    "        path = image_path,\n",
    "        width =width, height=height,\n",
    "         polygons=polygons)\n",
    " def load_mask(self, image_id):\n",
    "    \"\"\"Generate instance masks for an image.\n",
    "    Returns:\n",
    "    masks: A bool array of shape[height,width,instance count] with one mask per instance.\n",
    "    class_ids: a 1D array of class IDs of the instance masks.\n",
    "    \"\"\"\n",
    "    #If not a balloon dataset image,delegate to parent class.\n",
    "    image_info = self.image_info[image_id]\n",
    "    if image_info[\"source\"] != \"damage\":\n",
    "        return super(self._class_, self).load_mask(image_id)\n",
    "    \n",
    "    #Convert polygons to a bitmap mask of shape\n",
    "    #[height,width, instance_count]\n",
    "    info = self.image_info[image_id]\n",
    "    mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])], dtype=np.uint8)\n",
    "    for i,p in enumerate(info[\"polygons\"]):\n",
    "        #get indexes of pixels inside the polygon and set them to 1\n",
    "        rr, cc = skimage.draw.polygon(p['all_points_y'],p['all_points_x'])mask[rr,cc,i] = 1\n",
    "        #return mask, and array of class IDs of eeach instance.Since we have one class Id, we returnan array of 1s\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"damage\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self._class_,self).image_reference(image_id)\n",
    "            \n",
    "        def train(model):\n",
    "            \"\"\"Train the model.\"\"\"\n",
    "            #Training dataset.\n",
    "            dataset_train = CustomDataset()\n",
    "            dataset_train.load_custom(args.dataset,\"train\")\n",
    "            dataset_train.prepare()\n",
    "            \n",
    "            #Validation daatset\n",
    "            dataset_val = CustomDataset()\n",
    "            dataset_val.load_custom(args.dataset,\"val\")\n",
    "            dataset_val.prepare()\n",
    "            #***This training schedule is an example.\n",
    "            print(\"Training network heads\")\n",
    "            model.train(dataset_tarin,dataset_val,\n",
    "                       learning_rate=config.LEARNING_RATE,\n",
    "                       epochs=10,\n",
    "                       layers='heads')\n",
    "            \n",
    "            def color_splash(image,mask):\n",
    "                \"\"\"Apply color splash effect.\n",
    "                image: RGB image [height,width,3]\n",
    "                mask: instance segmetation mask[height,width,instance count]\n",
    "                Returns result image.\n",
    "                \"\"\"\n",
    "                # Make a grayscale copy of the image. The grayscale copy still \n",
    "                #has 3 RGB channels, though.\n",
    "                gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image))*255\n",
    "                # We're traeting all instances as one,so collapse the mask into one layer\n",
    "                mask = (np.sum(mask,-1,keepdims=True) >= 1)\n",
    "                #Copy color pixels from the original color image where mask is set\n",
    "                if mask.shape[0] > 0:\n",
    "                    splash = np.where(mask, image, gray).astype(np.uint8)\n",
    "                else:\n",
    "                    splash = gray\n",
    "                    return splash\n",
    "                \n",
    "                def detect_and_color_splash(model, image_path=None, video_path=None):\n",
    "                    assert image_path or video_path\n",
    "                    # Image or video?\n",
    "                    if image_path:\n",
    "                        #Run model detection and generate the color splash effect\n",
    "                        print(\"Running on {}\".format(args.image))\n",
    "                        #Read image\n",
    "                        image = skimage.io.imread(args.image)\n",
    "                        #Detect objects\n",
    "                        r = model.detect([image], verbose=1)[0]\n",
    "                        # Color splash\n",
    "                        splash = color_splash(image, r['masks'])\n",
    "                        # Save output\n",
    "                        file_name = \"splash_{:%Y%m%dT%H%M%S}.png\".format(datetime.now())\n",
    "                        skimage.io.imsave(file_name, splash)\n",
    "                        elif video_path:\n",
    "                            import cv2\n",
    "                            # Video capture\n",
    "                            vcapture = cv2.VideoCapture(video_path)\n",
    "                            width = int(vcapture.fet(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                            height = int(vcapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                            fps = vcapture.get(cv2.CAP_PROP_FPF)\n",
    "                        # Define codec and create video writer\n",
    "                        file_name =\"splash_{:%Y%m%dT%H%M%S}.avi\".format(datetime.datetime.now())\n",
    "                        vwriter - cv2.videoWriter(file_name,\n",
    "                                                 cv2>VideoWriter_fourcc(*'MJPG')\n",
    "                                                 fps,(width,height))\n",
    "                        count = 0\n",
    "                        success = True\n",
    "                        while success:\n",
    "                            print(\"frame:\", count)\n",
    "                            #Read next image \n",
    "                            success, iamge = vcapture.read()\n",
    "                            if success:\n",
    "                                # OpenCV returns image as BGR, convert to RGB\n",
    "                                image = image[...,::-1]\n",
    "                                # Detect Objects\n",
    "                                r = model.detect([image],verbose=0)[0]\n",
    "                                # Color splash \n",
    "                                splash = color_splash(image,r['masks'])\n",
    "                                # RGB -> BGR to save image to video\n",
    "                                splash = splash[...,::-1]\n",
    "                                #Add image to video writer\n",
    "                                vwriter.write(splash)\n",
    "                                count += 1\n",
    "                                vwriter.release()\n",
    "                                print(\"Saved to\",file_name)\n",
    "                                #########################################TRAINING####################################################\n",
    "                                \n",
    "                                if_name_ == '_main_':\n",
    "                                    import argparse\n",
    "                                    \n",
    "                                    #Parse command line arguments\n",
    "                                    parser = argparse.ArgumentParser(\n",
    "                                        description = 'Train Mask R-CNN to detect custom class.')\n",
    "                                    parser.add_argument(\"command\",\n",
    "                                                       metavar=\"<command>\",\n",
    "                                                        help=\"'train' or 'splash'\")\n",
    "                                    parser.add_argument('--dataset',required=False,\n",
    "                                                       metavar=\"/path/to/custom/dataset/\",\n",
    "                                                       help='Directory of the custom dataset')\n",
    "                                    parser.add_argument('--weights', required=True,\n",
    "                                                       metavar=\"/path/to/weights.h5\",\n",
    "                                                       help=\"Path to weights .h5 file or 'coco'\")\n",
    "                                    parser.add_argument('--logs', required=False,\n",
    "                                                       default=DEFAULT_LOGS_DIR,\n",
    "                                                       metavar=\"/path/to/logs\",\n",
    "                                                       help='Logs and checkpoints directory(default=logs/)')\n",
    "                                    parser.add_argument('--image', required=False,\n",
    "                                                       metavar=\"path or URL to image\",\n",
    "                                                       help='Image to apply the color splash effect on')\n",
    "                                    parser.add_argument('--video', required=False,\n",
    "                                                       metavar=\"path or URL to image\",\n",
    "                                                       help='Image to apply the color splash effect on')\n",
    "                                    args = parser.parse_args()\n",
    "                                    \n",
    "                                    #Validate arguments\n",
    "                                    if args.command == \"train\":\n",
    "                                        assert args.dataset,\"Argument --dataset is required for training\"\n",
    "                                    elif args.command ==\"splash\":\n",
    "                                        assert args.image or args.video,\\\n",
    "                                        \"Provide --image or --video to apply color splash\"\n",
    "                                        \n",
    "                                        print(\"Weights:\",args.weights)\n",
    "                                        print(\"Dataset:\",args.dataset)\n",
    "                                        print(\"Logs:\",args.logs)\n",
    "                                        \n",
    "                                        #Configurations\n",
    "                                        if args.command ==\"train\":\n",
    "                                            config = CustomConfig()\n",
    "                                            else:\n",
    "                                                class InferenceConfig(CustomConfig):\n",
    "                                                    # Set batch size to 1 since we'll be running inference on\n",
    "                                                    # one image at atime.Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "                                                    GPU_COUNT = 1\n",
    "                                                    IMAGES_PER_GPU = 1\n",
    "                                                    config = InferenceConfig()\n",
    "                                                    config.display()\n",
    "                                                    \n",
    "                                                    #create model\n",
    "                                                    if args.command == \"train\":\n",
    "                                                        model - modellib.MaskRCNN(mode= \"training\", config=config,\n",
    "                                                                                 model_dir=args.logs)\n",
    "                                                        else:\n",
    "                                                            model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                                                                                     model_dir=args.logs)\n",
    "                                            # Select weights file to load\n",
    "                                            if args.weights.lower()== \"coco\":\n",
    "                                                weights_path = COCO_WEIGHTS_PATH\n",
    "                                            \n",
    "                                            # Dowload weights file\n",
    "                                            if not os.path.exits(weights_path):\n",
    "                                                utils.dowload_trained_weights(weights_path)\n",
    "                                            elif args.weights.lower() == \"last\":\n",
    "                                                # Find last trained weights\n",
    "                                                weights_path = model.find_last()[1]\n",
    "                                            elif args.weights.lower() == \"imagenet\":\n",
    "                                                # Start from Imagenet trained weights\n",
    "                                                weights_path = model.get_imagenet_weights()\n",
    "                                            else:\n",
    "                                                weights_path = args.weights\n",
    "                                                \n",
    "                                            # Load weights\n",
    "                                            print(\"Loading weights\", weights_path)\n",
    "                                            if args.weights.lower() ==\"coco\"\n",
    "                                                # Exclude the last layers because they require a matching \n",
    "                                                # number of classes\n",
    "                                                model.load_weights(weights_path,by_name= True, exclude=[\"mrcnn_class_logits\",\"mrcnn_bbox_fc\",\"mrcnn_box\", \"mrcnn_mask\"])\n",
    "                                           else:\n",
    "                                            model.load_weights(weights_path, by_name= True)\n",
    "                                            \n",
    "                                            #Train or evaluate\n",
    "                                            if args.command ==\"train\":\n",
    "                                                train(model)\n",
    "                                            elif args.command ==\"splash\":\n",
    "                                                 detect_and_color_splash(model,image_path=args.image,video_path=args.video)\n",
    "                                            else:\n",
    "                                                print(\"'{}'is not recognized.\"\n",
    "                                                     \"Use 'train' or 'splash'\".format(args.command))\n",
    "                                    \n",
    "            \n",
    "            \n",
    "        \n",
    "    ############################SETUP.PY##############################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-9-ed9155d8a14a>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-ed9155d8a14a>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    [metadata]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#####################SETUP.CFG#############################################################3\n",
    " \n",
    "    [metadata]\n",
    "    description.file = README.md\n",
    "    license.file = LICENSE\n",
    "    requirements-file = requirements.txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-277bd1f3ed7c>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-277bd1f3ed7c>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    tensorflow>=1.3.0\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "###################################REQUIREMENTS.TXT#########################################\n",
    "numpy\n",
    "scipy\n",
    "pillow\n",
    "cython\n",
    "matplotlib\n",
    "scikit-image\n",
    "tensorflow>=1.3.0\n",
    "keras>=2.0.8\n",
    "opencv-python\n",
    "h5py\n",
    "imguag\n",
    "Ipython[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################### MANIFEST###########################\n",
    "include README.md\n",
    "include LICENSE\n",
    "include requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-54f981822b34>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-54f981822b34>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    from matplotlib.pyplot as plt\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "########################### VISUALIZE.PY#########################################\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import colorsys\n",
    "\n",
    "import numpy as np\n",
    "from skimage.measure import find_contours\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot as plt\n",
    "from matplotlib import patches, lines\n",
    "from matplotlib.patches import Polygon\n",
    "import IPython.display\n",
    "\n",
    "# ROOT DIRECTORY OF THE PROJECT\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)          # TO FIND LOCAL VERSION OF LIBRARY\n",
    "from mrcnn import utils\n",
    "\n",
    "\n",
    "\n",
    "###################################################################### VISUALIZATION #######################################################################\n",
    "def display_images(images,title=None, cols=4, cmap=None, norm=None, interpolation=None):\n",
    "    \"\"\"Display the given set of images, optionally with titles.\n",
    "    images: list or array of images, optionally with titles.\n",
    "    titles:optional.A list of titles to display with each image.\n",
    "    cols: number of images per row\n",
    "    cmap:Optional. Color map to use. For example, \"Blues\".\n",
    "    norm:Optional. A Normalize instance to map valves to colors.\n",
    "    interpolation/;Optional. Image interpolation to use for display.\n",
    "    \"\"\"\n",
    "    titles - titles if titles is not None else[\"\"]*len(images)\n",
    "    rows = len(images)// cols + 1\n",
    "    plt.figure(figsize=(14, 14*rows // cols))\n",
    "    i = 1\n",
    "    for image, title in zip(images, titles):\n",
    "        plt.subplot(rows,cols, i)\n",
    "        plt.title(title,fontsize=9)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image.astype(np.uint8), cmap=cmap,\n",
    "                  norm=norm, interpolation=interpolation)\n",
    "        i += 1\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def random_colors(N, bright=True):\n",
    "        \"\"\"\n",
    "        Generate random colors.\n",
    "        To get visually distinct colors, generate them in HSV space then convert to RGB.\n",
    "        \"\"\"\n",
    "        brightness = 1.0 if bright else 0.7\n",
    "        hsv = [(i /N, 1, brightness) for i in range(N)]\n",
    "        colors = list(map(Lamda c: colorsys.hsv_to_rgb(*c),hsv))\n",
    "        random.shuffle(colors)\n",
    "        return colors\n",
    "    \n",
    "    def apply_mask(image, mask, color, alpha=0.5):\n",
    "        \"\"\"Apply the given mask to the image.\n",
    "        \"\"\"\n",
    "        for c in range(3):\n",
    "            image[:, :, c] = np.where(mask ==1,\n",
    "                                     image[:, :, c]*\n",
    "                                     (1- alpha) + alpha*color[c]*255,\n",
    "                                     image[:, :, c])\n",
    "            return image\n",
    "        \n",
    "    def display_instances(images, boxes, masks, class_ids, class_names,\n",
    "                         scores = None, title = \"\",\n",
    "                         figsize=(16, 16), ax=None,\n",
    "                         show_mask=True, show_bbox=True,\n",
    "                         colors=None, captions=None):\n",
    "        \"\"\"\n",
    "        boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
    "        masks: [heigh, width, num_instances]\n",
    "        class_ids: [num_instances]\n",
    "        class_names: list of class names of the dataset\n",
    "        scores: (optional) confidence scores for each box\n",
    "        title: (optional) Figure title\n",
    "        show_mask, show_bbox: To show masks and bounding boxes or not\n",
    "        figsize: (optional) the size of the image\n",
    "        colors:(optional) An array or colors to use with each objects\n",
    "        captions: (optional) A list of strings to use as captions for each object\n",
    "        \"\"\"\n",
    "        #Number of instances\n",
    "        N = boxes.shape[0]\n",
    "        if not N:\n",
    "            print(\"\\n*** No instances to display ***\\n\")\n",
    "        else:\n",
    "            assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "            \n",
    "        #If no axis is passed, create one and automatically call show()\n",
    "        auto_show = False\n",
    "        if not ax:\n",
    "            _, ax = plt.subplots(1, figsize=figsize)\n",
    "            auto_show = True\n",
    "            \n",
    "        # generate random colors\n",
    "        \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
